# Notes from PDC/PRACE Introduction to MPI workshop
### May 27, 2020

Welcome to the workshop!

- Workshop webpage: https://www.pdc.kth.se/about/events/pdc-prace-online-course-writing-parallel-applications-using-mpi-1.982660

- This hackmd document: https://hackmd.io/@KTW/mpi-intro-may2020/edit

- Lesson material: https://github.com/PDC-support/introduction-to-mpi

Please make sure that you have a working setup:
- if you will be using Python, these two commands should work: 
`python -c "from mpi4py import MPI"`
`mpirun --version`
- if you will be using C/C++:
`mpicc --version`
`mpirun --version`
- if you will be using Fortran:
`mpif90 --version`
`mpirun --version`



## Questions and discussion

#### Please always post questions at the end of this document

- when doing mpirun -n 4 it complains that I do not have enough empty slots. How to know how much can I use? 
    - what is the output of ``nproc`` on your system?
    - nproc is not recognized in terminal...
    - The flag for oversubscribing (OpenMPI): ``--oversubscribe``
    - the ``--oversubscribe`` made it!

- and for any given HPC that I connect, is "nproc" the way to figure this out?
    - There are alternatives too, I like `lstopo` better because it gives you insight into the topology of the node as well 
    - You may want to read the documentation pages for the HPC site, to get an idea about the hardware and other specs. Sometimes hyperthreading is enabled but you may not want it. Sometimes the login node and the compute node have different architectures.


- I recently run MPI in python with 2 cores and compared with when using only one core and the execution times was the roughly the same. The code snippet that I run was computationally inexpensive so I guess this is why the behaviour was roughly the same. But I was wondering what is the threshold (code complexity) that I should start seeing difference in the execution time?
    - It boils down to how large part of your algorithm can be parallel vs. serial. [Amdahl's](https://www.kth.se/blogs/pdc/2018/11/scalability-strong-and-weak-scaling/) law shows that if the serial part of your algorithm dominates, scalability will be poor.

- What is the structure of MPI_COMM_WORLD (just wonder is there other variables beside rank, n_rank)? Does it share the same information data for all cores?
    - rank and n_rank are returned by MPI_Comm_rank and MPI_Comm_size, which take MPI_COMM_WORLD as one of the arguments. In that sense rank and n_rank do not "belong" to MPI_COMM_WORLD. The implementation detail of MPI_COMM_WORLD is beyond the scope of this workshop, and there are slight differences between e.g. MPICH and OpenMPI.
    - All cores have access to MPI_COMM_WORLD.
    
- Is there any difference between mpirun and mpiexec?
  - no they accomplish the same thing
  - apparently mpiexec is part of the MPI standard and perhaps slightly favored for that reason, but all MPI implementations also have mpirun 

- About the bad example for parallelization (old and new value): more generally, recursive algorithms cannot be parallelized?
    - Task level parallelism can help in some of such cases: https://youtu.be/AioeS_Jo0Yg?t=502
    
- Does the buffer have to have exactly the memory size of the data to be sent? Can I "oversize" my buffer?
    - oversize is ok. `count` determines how many elements should be sent/received starting from the buffer's base address.

- In the case of Python, which is quite easy-going with variables type and definitions: Can you send whatever kind of variables? Do you have to define the buffer and type?
    - Python handles the type
    - but if you need faster communication (essentially same speed as for C/Fortran) then you can use uppercase `Send` and `Recv` function with buffer-type objects like NumPy arrays

- I will try to convert a code from python2 to python3 and there are MPI commands there. Do you think that MPI will still run smoothly without changing the MPI commands or are there many things that have changed?
    - I haven't done the same thing, but I tend to agree with the instructor. Going from Python 2 to 3 should be OK; the other way may be more tricky.
    - Maybe also check that the mpi4py you are using is installed by pip from python3. If not sure you can reinstall mpi4py.
    - I have another environment for python3 so I installed again mpi4py at this env
    
- How can one implement correct placing of processes/threads over the numa_node/socket/cpu_core in C/C++? How to allocate 1 process/numa_node? How to allocate exactly 1 thread per logical core for given set of logical core ids?

-   I mean, that one should ideally divide the whole task in such way, that each host having N_numa_nodes, should run N_numa_nodes number of MPI processes, 1 per each numa_node and prevent subscribing several processes on one node. Moreover, migration of processes/threads is not very good, as if the memory was allocated on one numa_node and process migrated to another - then memory bandwidth will be much slower.
    - Very good question. Normally, one does not need to implement anything in the source code. This is taken care of at run time by the mpi launcher (e.g. mpiexec). They do have flags for specifying how many ranks per node / socket should be launched, and they also have flags for enforcing pinning to avoid process migration. Resource managers like SLURM also have flags for specifying those. In case of an OpenMP program, the OpenMP runtime provides such settings through envirinment variables to enforce thread pinning and placement.
    - "How to allocate exactly 1 thread per logical core for given set of logical core ids?" --> If the system administrator has enabled hyper-threading, SLURM gives you the possibility of not using the hyperthread by doing:
    `#SBATCH --cpus-per-task=2`
    otherwise, if hyperthreading is disabled, with `#SBATCH -n X` you get exactly X cores and consequently exactly X threads
    Similar settings are available for other resource managers.

 - I'd like to ask you one extra question about collective communications.
   - One can consider one manager and many workers, taking into account that workers are possibly heterogeneous and tasks to workers can take different time. Let's say that there are input  and output streams for manager. Workers ask for tasks from input stream, do calculations and send the results to the manager. Manager writes the results to output stream. Manager seems to send and receive data to/from workers simultaneously in order to avoid them idling.
   - How to check send/receive status of multiple packets at once?
   - Collective communication operations are blocking communications. All the processes will be synchronized during a collective call like MPI_Bcast, MPI_Scatter, MPI_Gather, etc. So one does not check the status of collective communication. The program only proceeds after the collective communication is finished.
   - If the workers and tasks are highly heterogeneous, it probably makes sense to use point-to-point communications, where the manager constantly checks the status of inidividual non-blocking send/receive status with each worker.
   - Ok thank you.
